---
title: "Assignment 2"
author: "Balint Parragi, `r Sys.Date()`"
geometry: left=1cm,right=1cm,top=1.5cm,bottom=1.5cm
fontsize: 8pt
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE)
```

```{r,include=FALSE}
library(tidyverse)
library(fixest)
library(data.table)
library(dplyr)
library(ggplot2)
library(caret)
library(kableExtra)
library(gridExtra)
library(grid)
```

```{css, echo=FALSE}
h1, h2, h3 , h4 {
  text-align: center;
  font-weight: bold;
}
```

```{r, include=FALSE}
listings <- fread("data/listings.csv",encoding = "UTF-8")
#midsize apartments, 2-6 guests

listings_clean <- listings %>% 
  select(-c(id,listing_url,scrape_id,last_scraped,source,picture_url,host_url,host_thumbnail_url,host_picture_url,host_neighbourhood,neighbourhood_group_cleansed,calendar_updated,license)) %>% 
  filter(room_type == "Entire home/apt",
         accommodates >= 2 & accommodates <= 6) %>% 
  mutate(price_usd = gsub(",","",price),
         price_usd = as.numeric(gsub("\\$","",price_usd)),
         bathrooms = str_extract(bathrooms_text,"([0-9]*[.])?[0-9]+"),
         bathrooms = ifelse(str_detect(tolower(bathrooms_text),"half"),"0.5",ifelse(bathrooms_text=="","0",bathrooms)),
         bathrooms = as.numeric(bathrooms),
         neighbourhood_cleansed = gsub("\u009f","ü",neighbourhood_cleansed),
         neighbourhood_cleansed = gsub("§","ß",neighbourhood_cleansed),
         neighbourhood_cleansed = gsub("\u009a","ö",neighbourhood_cleansed),
         neighbourhood_cleansed = gsub("\u008a","ä",neighbourhood_cleansed),
         f_neighbourhood_cleansed = factor(neighbourhood_cleansed),
         f_property_type = factor(property_type),
         host_response_rate = as.numeric(ifelse(host_response_rate %in% c("N/A",""),NA,gsub("%","",host_response_rate)))/100,
         host_acceptance_rate = as.numeric(ifelse(host_acceptance_rate %in% c("N/A",""),NA,gsub("%","",host_acceptance_rate)))/100,
        host_experience = as.numeric(as.Date(calendar_last_scraped,format="%Y-%m-%d") -
                                as.Date(host_since ,format="%Y-%m-%d")),
         amenities = gsub('\\\"\"',"",amenities),
         amenities = gsub("\\\\u00e9","é",amenities),
         amenities = gsub("\\\\u00f6","ö",amenities),
         amenities = gsub("\\\\u00fc","ü",amenities),
         amenities = gsub("\\\\u00df","ß",amenities),
         amenities = gsub("\\\\u00a0"," ",amenities),
         amenities = gsub("\\\\u00e4","ä",amenities),
         amenities = gsub("\\\\u2019","'",amenities),
         amenities = gsub("\\\\u2013","-",amenities),
         amenities = gsub("\\\\","″",amenities),
         amenities = gsub("\\[","",amenities),
         amenities = gsub("\\]","",amenities),
        amenities = tolower(amenities),
         host_is_superhost = ifelse(host_is_superhost=="t",1,ifelse(host_is_superhost=="f",0,NA)),
         host_has_profile_pic = ifelse(host_has_profile_pic=="t",1,ifelse(host_has_profile_pic=="f",0,NA)),
         host_identity_verified = ifelse(host_identity_verified=="t",1,ifelse(host_identity_verified=="f",0,NA)),
         has_availability = ifelse(has_availability=="t",1,ifelse(has_availability=="f",0,NA)),
        instant_bookable = ifelse(instant_bookable=="t",1,ifelse(instant_bookable=="f",0,NA)),
        accommodates_sq=accommodates^2, 
        ln_accommodates=log(accommodates) ,
        ln_accommodates_sq=log(accommodates)^2,
        ln_beds = log(beds),
        ln_bathrooms = log(bathrooms),
        ln_number_of_reviews = log(number_of_reviews+1),
        ln_price_usd = log(price_usd)) %>% 
  select(-c(room_type,bathrooms_text))

#dig into amenities. After preprocessing, I try to group them as much as possible
listings_clean <- listings_clean %>% 
  mutate(da_coffe = ifelse(str_detect(amenities,"coffee"),1,0),
         da_tv = ifelse(str_detect(amenities,"hdtv |tv "),1,0),
         da_coalarm = ifelse(str_detect(amenities,"carbon monoxide"),1,0),
         da_smokealarm = ifelse(str_detect(amenities,"smoke"),1,0),
         da_kitchen = ifelse(str_detect(amenities,"kitchen"),1,0),
         da_wifi = ifelse(str_detect(amenities,"wifi"),1,0),
         da_fastwifi = ifelse(str_detect(amenities,"fast wifi"),1,0),
         da_workspace = ifelse(str_detect(amenities,"workspace"),1,0),
         da_parking = ifelse(str_detect(amenities,"parking|carport"),1,0),#paid or free?
         da_cleaningprod = ifelse(str_detect(amenities,"cleaning products"),1,0),
         da_micro = ifelse(str_detect(amenities,"microw|mikrow|micro and oven"),1,0),
         da_oven = ifelse(str_detect(amenities,"oven"),1,0),
         da_cloth_store = ifelse(str_detect(amenities,"clothing storage|dresser"),1,0),
         da_bikes = ifelse(str_detect(amenities,"bikes"),1,0),
         da_fridge = ifelse(str_detect(amenities,"fri"),1,0),
         da_dishwasher = ifelse(str_detect(amenities,"dishwasher"),1,0),
         da_washer = ifelse(str_detect(amenities,"washer")&amenities!="dishwasher",1,0),
         da_lt_stay = ifelse(str_detect(amenities,"long term"),1,0),
         da_packnplay = ifelse(str_detect(amenities,"pack"),1,0),
         da_withview = ifelse(str_detect(amenities,"view|waterfront"),1,0),
         da_heating = ifelse(str_detect(amenities,"heating|heated")&amenities!="pool - heated",1,0),
         da_bathroom_ess = ifelse(str_detect(amenities,"bathroom essentials|bath tub soaps|shower gel|shampoo|body soap|conditioner"),1,0),
         da_balcony = ifelse(str_detect(amenities,"balcony"),1,0),
         da_backyard = ifelse(str_detect(amenities,"backyard"),1,0),
         da_smoking = ifelse(str_detect(amenities,"smoking"),1,0),
         da_children_book = ifelse(str_detect(amenities,"children's book"),1,0),
         da_pets = ifelse(str_detect(amenities,"pets"),1,0),
         da_ac = ifelse(str_detect(amenities,"air conditioning"),1,0),
         da_hairdryer = ifelse(str_detect(amenities,"hair dryer"),1,0),#very highly correlated with dryer, latter not included
         da_soundsystem = ifelse(str_detect(amenities,"sound system"),1,0),
         da_highchair = ifelse(str_detect(amenities,"high chair"),1,0),
         da_fan = ifelse(str_detect(amenities,"fan"),1,0),
         da_breakfast = ifelse(str_detect(amenities,"breakfast"),1,0),
         da_iron = ifelse(str_detect(amenities,"iron"),1,0),
         da_hostgreet = ifelse(str_detect(amenities,"host"),1,0),
         #da_selfcheckin = ifelse(str_detect(amenities,"self"),1,0),very highly correlated with the above
         da_boardgame = ifelse(str_detect(amenities,"board"),1,0),
         da_freezer = ifelse(str_detect(amenities,"freezer"),1,0),
         da_elevator = ifelse(str_detect(amenities,"elevator"),1,0),
         da_firstaid = ifelse(str_detect(amenities,"first"),1,0),
         da_toaster = ifelse(str_detect(amenities,"toaster"),1,0),
         da_babyfriendly = ifelse(str_detect(amenities,"baby"),1,0),
         da_fireext = ifelse(str_detect(amenities,"extinguisher"),1,0),
         da_stove = ifelse(str_detect(amenities,"stove"),1,0),
         da_kettle = ifelse(str_detect(amenities,"kettle"),1,0),
         da_singlelevel = ifelse(str_detect(amenities,"single level"),1,0),
         da_luxury = ifelse(str_detect(amenities,"private pool|private sauna|private beach|private indoor pool|private outdoor pool|private hot tub"),1,0),
         da_gym = ifelse(str_detect(amenities,"gym"),1,0),
         da_host_org = ifelse(str_detect(tolower(host_name),"apart|home|blueground|residence|hotel|living|flat|rental|vienna|suit|flarent|team|immo|gmbh|feelgood"),1,0),
         f_host_response_time =factor(ifelse(host_response_time=="","N/A",host_response_time)),
         availability_year_share = availability_365/365) %>% 
  select(-c(host_id,host_since,host_name,host_location,name,description,neighborhood_overview,host_about,host_verifications,host_response_time,host_listings_count,neighbourhood,latitude,longitude,amenities,price,calendar_last_scraped,property_type,neighbourhood_cleansed,minimum_minimum_nights,minimum_maximum_nights,maximum_minimum_nights,maximum_maximum_nights,availability_30,availability_60,availability_90,availability_365,number_of_reviews_ltm,number_of_reviews_l30d,first_review,last_review,starts_with("review_score"),starts_with("calculated"),host_response_rate,host_acceptance_rate,bedrooms,minimum_nights_avg_ntm,maximum_nights_avg_ntm,reviews_per_month,))

listings_clean <- listings_clean %>% 
  mutate(f_minimum_nights= cut(minimum_nights, c(1,2,3,max(listings_clean$minimum_nights)), labels=c(1,2,3), right = F))

listings_clean <- listings_clean %>% 
  mutate(bathrooms =  ifelse(is.na(bathrooms), median(bathrooms, na.rm = T),bathrooms), #assume at least 1 bath
    beds = ifelse(is.na(beds), accommodates, beds), #assume n_beds=n_accomodates
    f_minimum_nights=ifelse(is.na(f_minimum_nights),1, f_minimum_nights),
    ln_beds=ifelse(is.na(ln_beds),0, ln_beds),
    ln_bathrooms=ifelse(ln_bathrooms==-Inf,0, ln_bathrooms),
    host_experience = ifelse(is.na(host_experience), median(host_experience, na.rm = T),host_experience),
    host_total_listings_count = ifelse(is.na(host_total_listings_count), median(host_total_listings_count, na.rm = T),host_total_listings_count),
    host_has_profile_pic=ifelse(is.na(host_has_profile_pic),0, host_has_profile_pic),
    host_identity_verified=ifelse(is.na(host_identity_verified),0, host_identity_verified)) %>% 
  filter(price_usd <= 1000) %>% #99th percentile is 456, so it is not a binding threshold
  filter(host_total_listings_count<=1000) #also removing very a few data points

#Some character variables are not really meaningful or do not exhibit large variations
  #host location: mostly Vienna, empty, or (lower-) Austria
  #host verification: mostly email and/or phone
  #description/neighbourhood overview could be further extracted --> location, accessibility, floor, closeness of sights, amenities etc., but it is out of scope
  #and some are already used (to create a different feature), so they can be now dropped
  #review scores overall/in different areas: might be useful for a different model, but these are NEW listings, so reviews cannot help in the initial price setting (might help afterwards though). However, host attributes can matter as there is nothing about the host being new/existing with different listings

to_filter <- sapply(listings_clean, function(x) sum(is.na(x)))
to_filter[to_filter > 0]
```


# __Predicting Airbnb prices in small and medium-size apartments__

## Data collection

Data is from the <span style="text-decoration:underline">[Inside Airbnb site](http://insideairbnb.com/get-the-data.html)</span>, I selected the city of *Vienna* for the most recent time period available. The raw data consists of `r nrow(listings)` observations. After filtering for size (small and medium) and number of guests (2-6), and cleaning the data sufficiently, the sample size consists of `r nrow(listings_clean)` observations.

## Data exploration and dropping features

Several features of the data is not needed as

1. They are not conveying any information (large number of missing values which cannot be computed, very low variation, etc.)
2. They are not valid as this task is designed for new listings on the market
3. There are (or there can be created) other features that incorporate the characteristics of that feature as well

Based on these points, the following more important variables were dropped:

- review scores measures, listing's number of days on the market, host response rate, host acceptance rate, bedrooms
- some features needed imputed values - either with the median value, or if categorical, then by negative (false) value
- number of `NA`-s were very low in the remaining features --> required little imputation
-some variables could also be dropped from or united among amenities as they have high (0.6,0.7) correlation with each other, but at large samples this causes less severe problems. 

Finally, the target variable (*price usd*) needed filtering as there were some massive outlier in the data. However, a threshold of 1000$ was sufficient, which resulted in the loss of less than 1% of the data.

### Location

```{r,echo=FALSE,warning=FALSE,fig.align='center',fig.height=3.75,fig.width=6}
plot_listings <- listings_clean %>% 
  group_by(f_neighbourhood_cleansed) %>% 
  mutate(avg_price_usd = mean(price_usd,na.rm=T),
         count = n())

nh <- ggplot(plot_listings,aes(x = reorder(f_neighbourhood_cleansed,-avg_price_usd),y=price_usd))+
  geom_boxplot()+
  geom_text(aes(y = max(price_usd)*1.05,label=count),size = 2.5)+
  labs(x = "District", y="Price (USD)",caption = "Number of listings\nin each district in the upper part.")+
  theme_bw()+
  theme(axis.title = element_text(size = 9),
        axis.text = element_text(size = 7,color="black"),
        axis.text.x = element_text(size = 7,color="black",angle=90),
        plot.caption = element_text(size = 7.5))+
  scale_y_continuous(labels = scales::dollar_format())
nh
```

Using domain knowledge, I assume that location should be some of the most important factors in deciding the price. Unsurprisingly, Innere Stadt (first district) clearly stands out, it is much more expensive on average than any other districts in Vienna. Landstrasse (3rd), Wieden (4th), Josefstadt (8th) Mariahilf (6th) and Neubau (7th) are also on top as they constitute the inner, historic part of the city, close to the canal and several sights. Some others are on the shore of the Danube (Florisdorf, Leopoldstadt), which can come with better views. Also, Leopoldstadt contains the most observations, as it is both close to the Danube and to the center, ideal for people who are seeking entire apartments.

### Prices

```{r,echo=FALSE,fig.height=3.75,fig.width=6}
h1 <- ggplot(listings_clean,aes(x = price_usd))+
  geom_histogram()+
  labs(x = "Distribution of prices (USD)",caption = "Observations above $1000 are removed.")+
  theme_bw()+
  theme(axis.title.x = element_text(size = 9),
        axis.title.y = element_blank(),
        axis.text = element_text(size = 8,color="black"),
        plot.caption = element_text(size = 7.5))+
  scale_y_continuous(labels = scales::dollar_format())
h2 <- ggplot(listings_clean,aes(x = ln_price_usd))+
  geom_histogram()+
  labs(x = "Distribution of prices (log)",caption = "Observations above $1000 are removed.")+
  theme_bw()+
  theme(axis.title.x = element_text(size = 9),
        axis.title.y = element_blank(),
        axis.text = element_text(size = 8,color="black"),
        plot.caption = element_text(size = 7.5))

grid.arrange(h1,h2,nrow=1,ncol=2)

h <- arrangeGrob(h1,h2,nrow=1,ncol=2)
```

Prices are as usual in the data: very skewed to the left, and mostly below 500 USD/night with a mean around `r mean(listings_clean$price_usd,na.rm=T)`. The log price plot shows a much clearer view, more resembling to normally distributed.

### Accommodates

```{r,echo=FALSE,fig.height=3.75,fig.width=6}
a1 <- ggplot(listings_clean,aes(x = as.factor(accommodates), y = price_usd,fill=as.factor(accommodates)))+
  geom_boxplot()+
  labs(x = "Accommodates",y="Price (USD)")+
  theme_bw()+
  theme(axis.title = element_text(size = 9),
        axis.text = element_text(size = 8,color="black"),
        legend.position = "none")+
  scale_y_continuous(labels = scales::dollar_format())+
  scale_fill_brewer(palette = "Paired")

a2 <- ggplot(listings_clean,aes(x = as.factor(accommodates), y = ln_price_usd,fill=as.factor(accommodates)))+
  geom_boxplot()+
  labs(x = "Accommodates",y="Price (log)")+
  theme_bw()+
  theme(axis.title = element_text(size = 9),
        axis.text = element_text(size = 8,color="black"),
        legend.position = "none")+
  scale_fill_brewer(palette = "Paired")

grid.arrange(a1,a2,nrow=1,ncol=2)
```

Prices are increasing with number of accommodates, which is again not surprising. The nominal price plot show a larger variability, differences between the log categories are more subtle.

```{r,echo=FALSE,fig.height=3.75,fig.width=6}
b1 <- ggplot(listings_clean,aes(x = as.factor(da_parking), y = price_usd,fill=as.factor(da_parking)))+
  geom_boxplot()+
  labs(x = "Parking spot available",y="Price (USD)")+
  theme_bw()+
  theme(axis.title = element_text(size = 9),
        axis.text = element_text(size = 8,color="black"),
        legend.position = "none")+
  scale_y_continuous(labels = scales::dollar_format())+
  scale_x_discrete(labels = c("0"="No","1"="Yes"))+
  scale_fill_manual(values = c("red","steelblue"))
b2 <- ggplot(listings_clean,aes(x = as.factor(da_ac), y = price_usd,fill=as.factor(da_ac)))+
  geom_boxplot()+
  labs(x = "Air conditioning",y="Price (USD)")+
  theme_bw()+
  theme(axis.title = element_text(size = 9),
        axis.text = element_text(size = 8,color="black"),
        legend.position = "none")+
  scale_y_continuous(labels = scales::dollar_format())+
  scale_x_discrete(labels = c("0"="No","1"="Yes"))+
  scale_fill_manual(values = c("red","steelblue"))

b3 <- ggplot(listings_clean,aes(x = as.factor(da_smoking), y = price_usd,fill=as.factor(da_smoking)))+
  geom_boxplot()+
  labs(x = "Smoking is allowed",y="Price (USD)")+
  theme_bw()+
  theme(axis.title = element_text(size = 9),
        axis.text = element_text(size = 8,color="black"),
        legend.position = "none")+
  scale_y_continuous(labels = scales::dollar_format())+
  scale_x_discrete(labels = c("0"="Not allowed","1"="Allowed"))+
  scale_fill_manual(values = c("red","steelblue"))

b4 <- ggplot(listings_clean,aes(x = beds, y = price_usd,color = as.factor(instant_bookable)))+
  geom_point()+
  labs(x = "Number of beds",y="Price (USD)")+
  theme_bw()+
  theme(axis.title = element_text(size = 9),
        axis.text = element_text(size = 8,color="black"),
        legend.title = element_text(size = 8),
        legend.position = c(0.85,0.85))+
  scale_y_continuous(labels = scales::dollar_format())+
  scale_color_manual(name="Instantly bookable",labels=c("0"="No","1"="Yes"),
                     values = c("red","steelblue"))
grid.arrange(b1,b2,b3,b4,nrow=2,ncol=2,
             bottom = textGrob("Observations above $1000 are removed.",hjust = 0,x=0.6,gp = gpar(fontsize = 7)))
```

Other features show that listings having air-conditioning, (bit counterintuitively) being non-smoking are more expensive. Parking spots seemingly do not lead to any price difference. Number of beds - most likely because it is linked to number of accommodates - has a positive relationship with prices as well as the possibility of instant booking.

## Models and methods used

The target variable is **nightly price** across all models.

1. Model 1: OLS model; $accommodates+beds+property\:type+bathrooms+neighbourhood + instant\:bookable + host\:attributes$
2. Model 2: OLS model; $Model_1 + accommodates^2$
3. Model 3: OLS model; $Model_2 + interactions$
4. Model 4: OLS model; $Model_1 + amenities$ ($Model_1$ sic!)
5. Model 5: OLS model; $Model_2 + amenities$
6. Model 6: LASSO, based on $Model_4$
7. Model 7: Random Forest with basic tuning

The interactions are based on domain knowledge and include: 

- $accommodates\times property\;type$, $air conditioning\times property\;type$, $pets\times property\;type$
- $accommodates\times neighbourhood$, $property\;type\times neighbourhood$


```{r,echo=FALSE,warning=FALSE}
#OLS and LASSO
# Selecting  and categorising features
basic_vars <- c(
  'accommodates', 'beds',
  'f_property_type','bathrooms',
  'f_neighbourhood_cleansed','instant_bookable')

# host attributes
host <- c("host_is_superhost","host_has_profile_pic",
          "host_total_listings_count","host_identity_verified","host_experience")

# Dummy variables
amenities <-  grep('^da_.*', names(listings_clean), value = TRUE)

#polynomials
poly_lev <- c('accommodates_sq')

#interactions for the LASSO
X1  <- c('accommodates*f_property_type',
         'da_ac*f_property_type', 'da_pets*f_property_type')
# with districts
X2  <- c('f_property_type*f_neighbourhood_cleansed',
         'accommodates*f_neighbourhood_cleansed')

model_ols1 <- paste0(' ~ ',paste(c(basic_vars,host),collapse = ' + '))
model_ols2 <- paste0(' ~ ',paste(c(basic_vars,host,poly_lev),collapse = ' + '))
model_ols3 <- paste0(' ~ ',paste(c(basic_vars,host,poly_lev,X1,X2),collapse = ' + '))
model_ols4 <- paste0(' ~ ',paste(c(basic_vars,host,poly_lev,amenities),collapse = ' + '))
model_ols5 <- paste0(' ~ ',paste(c(basic_vars,host,poly_lev,X1,X2,amenities),collapse = ' + '))

set.seed(0201)
train_indices <- as.integer(createDataPartition(listings_clean$price_usd, p = 0.75, list = FALSE))
data_train    <- listings_clean[train_indices, ]
data_holdout  <- listings_clean[-train_indices, ]
data_work <- data_train

k_folds <- 5
seed_val <- 20230210

for (i in 1:5){
  model_name <-  paste0('model_ols',i)
  model_pretty_name <- paste0('M',i,'')
  yvar <- 'price_usd'
  xvars <- eval(parse(text = model_name))
  formula <- formula(paste0(yvar,xvars))
  model_work_data <- feols(formula, data = data_work, vcov='hetero')
  
  fs  <- fitstat(model_work_data,c('rmse','r2','bic'))
  BIC <- fs$bic
  r2  <- fs$r2
  rmse_train <- fs$rmse
  ncoeff <- length(model_work_data$coefficients)
  set.seed(seed_val)
  cv_i <- train(formula, data_work, method = 'lm', 
                 trControl = trainControl(method = 'cv', number = k_folds))
  rmse_test <- mean(cv_i$resample$RMSE)
  model_add <- tibble(Model=model_pretty_name, Coefficients=ncoeff,
                      R_squared=round(r2,digits=3), BIC = round(BIC,digits = 1), 
                      Training_RMSE = round(rmse_train,digits=3),
                      Test_RMSE = round(rmse_test,digits = 3))
  if (i == 1){
    model_results <- model_add
  } else{
    model_results <- rbind(model_results, model_add)
  }
}
model_results %>%  kable(align = "c")%>% 
  kable_styling(latex_options = "hold_position",
                full_width=FALSE,position = "center",font_size = 9)
```

$Model_4$ stands as the best model of these five with lowest Test RMSE and BIC. It indicates that amenities are needed in general, but the interactions do not improve the model fit (even more so, worsening the fit by much), but still, the most complex model's ($Model_5$) performance is not bad either. Plotting Test and Train RMSE-s shows the same.

```{r,echo=FALSE,fig.height=3.75,fig.width=6}
# RMSE training vs test graph
colors = c('Training RMSE'='red','Test RMSE' = 'steelblue')
rmse<-ggplot(data = model_results, aes(x = factor(Coefficients), group = 1))+
  geom_line(aes(y = Training_RMSE, color = 'Training RMSE'), size = 1) +
  geom_line(aes(y = Test_RMSE, color = 'Test RMSE'), size = 1)+
  labs(subtitle = "Training and test RMSE versus model complexity",y='RMSE',x='Number of coefficients',color = '')+
  scale_color_manual(values = colors)+
  theme_bw()+
  theme(axis.text = element_text(color="black",size = 8),
        axis.title = element_text(color="black",size = 9),
        plot.subtitle = element_text(size = 10.5,hjust =0.5),
        legend.position='bottom')
rmse
```

## LASSO based on the best OLS

Next model (LASSO) is based on $Model_4$. After a basic tuning (only parameter here is $\lambda$), the following plot shows which tuning parameter is the most optimal.

```{r,echo=FALSE,fig.height=3.75,fig.width=6}
#Create Lasso

vars_model_4 <- c('price_usd',basic_vars,host,poly_lev,amenities)

train_control <- trainControl(method = 'cv', number = k_folds)
tune_grid     <- expand.grid('alpha' = c(1), 'lambda' = seq(0.05, 1, by = 0.05))
formula <- formula(paste0('price_usd ~ ', paste(setdiff(vars_model_4, 'price_usd'), collapse = ' + ')))

set.seed(seed_val)
lasso_model <- caret::train(formula,
                      data = data_work,
                      method = 'glmnet',
                      preProcess = c('center', 'scale'),
                      trControl = train_control,
                      tuneGrid = tune_grid,
                      na.action=na.exclude)
lasso_fitstats <- lasso_model$results %>%
  filter(lambda == lasso_model$bestTune$lambda) 

plot(lasso_model)
```

The best $\lambda$ is `r lasso_model$bestTune$lambda`, this is where the cross-validated RMSE is the lowest.

```{r,include=FALSE}
lasso_coeffs <- coef(lasso_model$finalModel, lasso_model$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = 'variable') %>%
  rename(coefficient = `s1`)

lasso_coeffs_nz<-lasso_coeffs %>%
  filter(coefficient!=0)

lasso_coeffs_zero <- lasso_coeffs %>%
  filter(coefficient==0)
lasso_add <- tibble(Model='LASSO', Coefficients=nrow(lasso_coeffs_nz),
                    R_squared=round(lasso_fitstats$Rsquared,digits = 3), BIC = NA, 
                    Training_RMSE = NA, Test_RMSE = round(lasso_fitstats$RMSE,digits = 3))
# Add it to final results
model_results2 <- rbind(model_results, lasso_add)

```

Many coefficients - `r nrow(lasso_coeffs_zero)` out of `r nrow(lasso_coeffs)` - has been shrunk to zero, mostly property types (because of low sample size each), a few districts and several amenities dummy (f.e all the ones related to babies-children). These features apparently are among the ones that did not improve the fit as much as they increased the variance according to the algorithm.

```{r,echo=FALSE}
model_results2 %>%  kable(align = "c")%>% 
  kable_styling(latex_options = "hold_position",
                full_width=FALSE,position = "center",font_size = 9)
```

The LASSO model produces a better Test RMSE, indicating that it might be a better model than the previously seen OLS models.

## Random Forest (RF)

Going one step further, now using RF in order to predict Airbnb prices. Then, there is no need to define functional form and choose which variables to include. It only needs a stopping rule (depth rule, minimum node size), splitting rule (square root of features) and number of trees to grow, I define two models with somewhat different parameters to decide which provides a better fit.

```{r,echo=FALSE}
predictors_1 <- c(basic_vars)
predictors_2 <- c(basic_vars, host, amenities)
predictors_E <- c(basic_vars, host, amenities, X1,X2)

# do 5-fold CV
train_control <- trainControl(method = 'cv',
                              number = 5,
                              verboseIter = FALSE)
#Tuning
tune_grid <- expand.grid(
  .mtry = c(5, 7, 9),
  .splitrule = "variance",
  .min.node.size = c(5, 10)
)
# model 1
set.seed(12345)
rf_model_1 <- train(
  formula(paste0("price_usd ~", paste0(predictors_1, collapse = " + "))),
  data = data_train,
  method = "ranger",
  trControl = train_control,
  tuneGrid = tune_grid,
  importance = "impurity"
)
# model2
tune_grid <- expand.grid(
  .mtry = c(8, 10, 12),
  .splitrule = "variance",
  .min.node.size = c(5, 10, 15)
)

set.seed(12345)
rf_model_2 <- train(
  formula(paste0("price_usd ~", paste0(predictors_2, collapse = " + "))),
  data = data_train,
  method = "ranger",
  trControl = train_control,
  tuneGrid = tune_grid,
  importance = "impurity"
)
results <- resamples(
  list(
    model_1  = rf_model_1,
    model_2  = rf_model_2
  )
)

rf_tuning_modelB <- rf_model_2$results %>%
  dplyr::select(mtry, min.node.size, RMSE) %>%
  dplyr::rename(nodes = min.node.size) %>%
  spread(key = mtry, value = RMSE)

result_1 <- matrix(c(
                     rf_model_1$finalModel$mtry,
                     rf_model_2$finalModel$mtry,
                     rf_model_1$finalModel$min.node.size,
                     rf_model_2$finalModel$min.node.size,
                     round(mean(results$values$`model_1~RMSE`),digits=3),
                     round(mean(results$values$`model_2~RMSE`),digits = 3)),
                    nrow=2, ncol=3,
                    dimnames = list(c("Model 1", "Model 2"),
                                    c("Min vars","Min nodes","RMSE")))

result_1 %>% kable(align = "c")%>% 
  kable_styling(latex_options = "hold_position",
                full_width=FALSE,position = "center",font_size = 9)
```

Decision: model 2 is selected with minimum node size at `r rf_model_2$finalModel$min.node.size` and selected variables to split equal to `r rf_model_2$finalModel$mtry`. With this RF model, I plot the variables with their respective importance to decrease the variance of the model in three ways:

- Total (above an importance threshold)
- Best 10 
- Grouped according to broader features and factor types

```{r,include=FALSE}
#Preparing for plotting: grouping, cleaning var names and creating importance cutoff (above 500)

group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(ranger::importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}
rf_model_2_var_imp <- ranger::importance(rf_model_2$finalModel)/1000
rf_model_2_var_imp_df <-
  data.frame(varname = names(rf_model_2_var_imp),imp = rf_model_2_var_imp) %>%
  mutate(varname = gsub("f_neighbourhood_cleansed", "District: ", varname) ) %>%
  mutate(varname = gsub("f_property_type", "Property type: ", varname) ) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))
cutoff = 500

varnames <- rf_model_2$finalModel$xNames
f_neighbourhood_cleansed_varnames <- grep("f_neighbourhood_cleansed",varnames, value = TRUE)
f_property_type_varnames <- grep("f_property_type",varnames, value = TRUE)
f_host_varnames <- grep("host",varnames, value = TRUE)
d_amenities_varnames <- grep("da_",varnames, value = TRUE)


groups <- list(f_neighbourhood_cleansed=f_neighbourhood_cleansed_varnames,
               f_property_type = f_property_type_varnames,
               host = f_host_varnames,
               bathrooms = "bathrooms",
               accommodates = "accommodates",
               d_amenities = d_amenities_varnames)

rf_model_2_var_imp_grouped <- group.importance(rf_model_2$finalModel, groups)
rf_model_2_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_2_var_imp_grouped),
                                            imp = rf_model_2_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))
```

```{r,echo=FALSE,fig.height=3.75,fig.width=6}
cutoff = 500
vip1 <- ggplot(rf_model_2_var_imp_df[rf_model_2_var_imp_df$imp>cutoff,],
                                  aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(size=1.5) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage),size=1)+
  labs(title="Variable importance plot",y = 'Importance (Percent)', x= 'Variable name',caption = "Importance threshold above 500.") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw() +
  theme(axis.text = element_text(size=7,color="black"),
        axis.title = element_text(size=8,color = "black"),
        plot.title = element_text(size =10,hjust =0.5),
        plot.caption = element_text(size = 7))
vip1
```

```{r,echo=FALSE,fig.height=3.75,fig.width=6}
#top10
vip2 <- ggplot(rf_model_2_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), size=0.75) +
  labs(title="Variable importance plot - Best 10",y = 'Importance (Percent)', x= 'Variable name',caption = "Top 10 features.") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()+
  theme(axis.text = element_text(size=7,color="black"),
        axis.title = element_text(size=8,color = "black"),
        plot.title = element_text(size =10,hjust =0.5),
        plot.caption = element_text(size = 7))
vip2
```

```{r,echo=FALSE,fig.height=3.75,fig.width=6}
vip3 <-ggplot(rf_model_2_var_imp_grouped_df, aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), size=0.75) +
  labs(title="Variable importance plot - Grouped",y = 'Importance (Percent)', x= 'Variable name',caption = "Top 10 features.") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw()+
  theme(axis.text = element_text(size=7,color="black"),
        axis.title = element_text(size=8,color = "black"),
        plot.title = element_text(size =10,hjust =0.5),
        plot.caption = element_text(size = 7))
vip3
```


## Model comparison and evaluation

The final and arguably the most important part is the model evaluation, how the specified models perform on the holdout set and how accurate the prices predictions are.
But before, let us have a final look at the Test RMSE comparison of all the models.

```{r,echo=FALSE}
test_rmse_table <- data.table(c(t(model_results2$Test_RMSE),round(result_1[2,3],digits = 3))) %>% t()
colnames(test_rmse_table) <- c(c(model_results2$Model),"Random Forest")
rownames(test_rmse_table) <- "Test RMSE"
test_rmse_table %>% kable(align = "c")%>% 
  kable_styling(latex_options = "hold_position",
                full_width=FALSE,position = "center",font_size = 9)
```

```{r,echo=FALSE}
#evaluate
m4 <- feols(formula(paste0('price_usd',model_ols4)), data = data_work, vcov = 'hetero')
m5 <- feols(formula(paste0('price_usd',model_ols5)), data = data_work, vcov = 'hetero')

# Make prediction for the hold-out sample with each models
m4_p <- predict(m4, newdata = data_holdout)
m5_p <- predict(m5, newdata = data_holdout)
mL_p <- predict(lasso_model, newdata = data_holdout)
mRF_p <- predict(rf_model_2, newdata = data_holdout)

# Calculate the RMSE on hold-out sample
m4_rmse <- RMSE(m4_p,data_holdout$price_usd)
m5_rmse <- RMSE(m5_p,data_holdout$price_usd)
mL_rmse <- RMSE(mL_p,data_holdout$price_usd)
mRF_rmse <- RMSE(mRF_p,data_holdout$price_usd)
# Create a table
predict_table <- data.frame(rbind(m4_rmse,m5_rmse,mL_rmse,mRF_rmse)) %>% round(digits = 3)
rownames(predict_table) <- c('Model 4','Model 5','LASSO',"Random Forest")
colnames(predict_table) <- c('RMSE on hold-out sample')

data_holdout <- data_holdout %>% 
  cbind(m4_p,m5_p,mL_p,mRF_p)

predict_table %>% kable(align = "c")%>% 
  kable_styling(latex_options = "hold_position",
                full_width=FALSE,position = "center",font_size = 9)
```

The Random Forest model provides a clearly lower RMSE on the holdout sample fit, meaning it can predict prices with a little lower error on average. As a conclusion, this should be the chosen model for price prediction.

## Additional plots on prediction

Price predictions can be shown via scatter plots as well - we might discover some unique patterns.

```{r,echo=FALSE,fig.height=3.75,fig.width=6}
predict_plot <- data_holdout %>% 
  select(price_usd,m4_p,m5_p,mL_p,mRF_p) %>% 
  rename(`OLS Model 4` = m4_p,
         `OLS Model 5` = m5_p,
         LASSO = mL_p,
         `Random Forest` = mRF_p) %>% 
  melt(id.vars = "price_usd") %>% 
  rename(model = variable,
         predicted_price = value)

ggplot(predict_plot,aes(x = price_usd,y=predicted_price))+
  geom_point(color="lightblue")+
  geom_abline(intercept = 0, slope = 1,color="black",linetype = "dashed")+
  labs(x = "Actual price (USD)",y="Predicted price (USD)")+
  theme_bw()+
  theme(axis.text = element_text(size=7,color="black"),
        axis.title = element_text(size=8,color = "black"),
        plot.title = element_text(size =10,hjust =0.5),
        strip.background = element_blank())+
  facet_wrap(.~model)

```



